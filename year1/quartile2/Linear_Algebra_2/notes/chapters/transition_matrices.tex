\section{Transition Matrices}

We can find matrices for linear maps $\mathbb{K}^n \to \mathbb{K}^m$ by using the standard basis of $\mathbb{K}^n$ and $\mathbb{K}^m$.
However, working with abstract vector spaces, we do not have a standard basis. For that reason we look at transition matrices.

\subsection{Coordinates}
\begin{definition}[Coordinates]
    Let $V$ be an n-dimensional vector space with basis $\alpha = \{\vec{a}_1, \dots, \vec{a}_n\}$. Every vector $\vec{v} \in V$ can be
    expressed as a linear combination of the basis vectors in exactly one way:
    % Let $V$ be a vector space with basis $\mathscr{B} = \{\vec{v}_1, \vec{v}_2, \cdots, \vec{v}_n\}$. Let $\vec{v} \in V$. Then there exists unique $\lambda_1, \lambda_2, \cdots, \lambda_n \in \mathbb{K}$ such that
    \begin{equation}
        \vec{v} = \sum_{i=1}^n \lambda_i \vec{a}_i.
    \end{equation}
    The coordinates of $\vec{v}$ with respect to $\alpha$ are the numbers $\lambda_1, \lambda_2, \cdots, \lambda_n$.
\end{definition}

\begin{remark}
    Clearly, the coordinates depend on the choice of the basis $\alpha$.
\end{remark}

\begin{example}
    Consider the vector space $V$ of real polynomials of degree at most 2, and take the polynomial $p := 1+2x+3x^2$. Let $\alpha := \{1,x,x^2\}$ be a basis of $V$.
    The $\alpha$-coordinates of $p$ are $(1,2,3)$
\end{example}

\begin{theorem}
    Let $V$ be an n-dimensional vector space with basis $\alpha = \{\vec{a}_1, \dots, \vec{a}_n\}$. We will denote the
    map sending each vector $\vec{v}$ to its coordinates with respect to $\alpha$ by $\alpha$.

    Then $\alpha$ is an invertible linear map from $V$ to $\mathbb{K}^n$.
\end{theorem}

With this notation, $\alpha(\vec{v})$ is the coordinate vector of the vector $\vec{v} \in V$ with respect to the basis $\alpha$. 

\begin{definition}[Coordinate transformation (map)]
    Let $\alpha$ and $\beta$ be bases of an n-dimensional vector space $V$. The map $\beta\alpha\inv: \mathbb{K}^n \to \mathbb{K}^n$
    is called the coordinate transformation (map) from $\alpha$ to $\beta$.
\end{definition}

\subsection{Basis transition matrix}

\begin{definition}[Transition matrix]
    Let $\alpha$ and $\beta$ be bases of an n-dimensional vector space $V$. We call the $n \times n$-matrix associated
    to the linear map $\beta\alpha\inv$ the transition matrix from basis $\alpha$ to basis $\beta$ and denote it by $_\beta S _\alpha$.
\end{definition}

The following theorem states that multiplication with the matrix $_\beta S _\alpha$ translates $\alpha$- into $\beta$-coordinates,
and gives a direct description of how the matrix looks, entry-wise.

\begin{theorem}
    Let $\alpha$ and $\beta$ be bases of an n-dimensional vector space $V$ and let $_\beta S _\alpha$ be the basis transition matrix,
    i.e. the matrix of $\beta\alpha\inv$. Let $\vec{x}:=\alpha(\vec{v})$ be the $\alpha$-coordinate vector of a vector $\vec{v} \in V$.
    Then the $\beta$-coordinate vector of $\vec{v}$ is equal to the product $_\beta S _\alpha \vec{x}$. Furthermore, the columns
    of matrix $_\beta S \alpha$ are the $\beta$-coordinate vectors of the $\alpha$-basis vectors.
\end{theorem}

\begin{remark}
    $$_\alpha S {_\beta} {_\beta} S _\alpha = I, \text{ so } _\alpha S _\beta = _\beta S _\alpha \inv$$
\end{remark}

\begin{theorem}
    Let $\alpha, \beta$ and $\gamma$ be bases of an n-dimensional vector space $V$, with respective basis transition
    matrices $_\beta S _\alpha$ and $_\gamma S _\beta$. Then the basis transition matrix from $\alpha$ to $\gamma$ is
    $_\gamma S _\alpha = {_\gamma} S _\beta {_\beta} S _\alpha$.
\end{theorem}

\begin{remark}
    It is important to distinguish between calculating with vectors (so elements of the vectors space $V$) and calculating
    with coordinates (so sequences of elements from $\mathbb{K}^n$).
\end{remark}

\subsection{Generalizing the map-matrix connection for spaces that aren't \texorpdfstring{$\mathbb{K}^n$}{K}}

\begin{definition}[Matrix of a linear map]
    Let $V$ and $W$ be vector spaces with bases $\alpha$ and $\beta$ respectively. Let $\mathscr{A}: V \to W$ be a linear map.
    We denote the matrix of the linear map $\beta\mathscr{A}\alpha\inv$ by $_\beta A _\alpha$ and call it the matrix
    of $\mathscr{A}$ with respect to the bases $\alpha$ and $\beta$.
\end{definition}

\begin{remark}
    If $V = W$ and $\alpha = \beta$, then we simplify notation by denoting the corresponding matrix by $A_\alpha$.
    We call it the matrix of $\mathscr{A}$ with respect to the basis $\alpha$.
\end{remark}

\begin{remark}[How does the matrix look?]
    The columns of $_\beta A \alpha$ are
    $$(\beta\mathscr{A}\alpha\inv)(\vec{e}_i) = \beta(\mathscr{A}\vec{a}_i), \qquad i = 1,\dots,n,$$
    meaning the i-th column consists of the $\beta$-coordinates of the image $\mathscr{A}\vec{a}_i$ of the i-th basis vector $\vec{a}_i$.
\end{remark}

\begin{remark}
    To find the image of a vector $\vec{v} \in V$, we can:
    \begin{enumerate}
        \item Determine the coordinate vector $\alpha(\vec{v})$ of $\vec{v}$;
        \item Multiply $\alpha(\vec{v})$ with the representation matrix $_\beta A _\alpha$, yielding the coordinate vector
            of $\mathscr{A}\vec{v}$;
        \item Translate the coordinate vector of $\mathscr{A}\vec{v}$ back to the corresponding vector in $W$.
    \end{enumerate}
\end{remark}

\subsection{How do base changes affect the matrix of a linear map?}

\begin{theorem}[Effect of change of basis]
    Choose in a finite-dimensional space $V$ two bases $\alpha$ and $\beta$, and suppose $\mathscr{A}: V \to V$ is linear. Then
    $$A_\beta = {_\beta S _\alpha} {A_\alpha} {_\alpha S _\beta}.$$
\end{theorem}

