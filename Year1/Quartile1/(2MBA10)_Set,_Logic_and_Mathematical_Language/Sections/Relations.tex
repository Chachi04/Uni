\section{Relations}
\subsection{Binary relations}
\begin{definition}[Ralation]
    A relation $R$ between the sets $S$ and $T$ is a subset of the Cartesian product $S \times T$.  \par
    Suppose $R$ is a relation between $S$ and $T$. If $(a,b) \in R$, we say $a$ is in relation $R$ to $b$ ($aRb$).  \par
    $S$ is called the domain, while $S$ - \emph{codomain}. \par
    If $S=T$ we say $R$ is a relation on $S$.
\end{definition}
\begin{example}
    We give some examples:
    \begin{enumerate}
        \item $ R \{(0,0), (1,0), (2,1)\} $ is a relation between sets $ S = \{0,1,2\} $ and $ T = \{0,1\} $
        \item $ R = \{(x,y) \in \mathbb{R}^2 \mid y = x^2 \} $ is a relation on $ \mathbb{R} $
        \item Let $ \Omega $ be a set, then "is a subset of" $ \subseteq $ is a relation on the set $S = \mathcal{P}(\Omega)$ of all subsets of $ \Omega $
    \end{enumerate}
\end{example}

\begin{definition}[Image]
    Let $R$ be a relation from a set $S$ to a set $T$. Then for each element $a \in S$ we define $ \left[a\right]_R $ to be the set
    $$ \left[a\right]_R := \left\{b \in T \mid aRb\right\}$$
    (Sometimes this set is also denoted by $ R(a) $) This set is called the $(R-)$ image of $a$. \par
    For $b \in T$ the set
    $$ _R\left[b\right] := \left\{a \in S \mid aRb\right\} $$
\end{definition}

Relations between finite sets can be described using matrices.
\begin{definition}[Adjecency Matrix]
    If $ S = \left\{s_1, s_2, \dots, s_n\right\} $ and $ T = \left\{t_1, t_2, \dots, t_m\right\} $ are finite sets
    and $ R \subseteq S \times T $ is a binary relation, then the \emph{adjecency} matrix $ A_R $ of the relation $ R $ is the $ n \times m $ matrix
    whose rows are indexted by $S$ and columns by $T$ defined by:
    $$ A_{s,t} = \begin{cases}
        1 &\text{ if } (s,t) \in R \\
        0 &\text{ otherwise }
    \end{cases} $$
\end{definition}

\begin{example}
    \begin{enumerate}
        \item The adjecency matrix of the relation $ R = \left\{\left(0,0\right), \left(1,0\right),\left(2,1\right)\right\} $ between the sets $ S = \left\{0,1,2\right\} $ and $ T = \left\{0,1\right\} $ equals
        $$ \begin{pmatrix}
            1 & 0 \\
            1 & 0 \\
            0 & 1
        \end{pmatrix} $$
        \item The adjecency matrix of the identity relation on a set $S$ of size n:
        $$ I_n = \begin{pmatrix}
            1 & 0 & \dots & 0 & 0 \\
            0 & 1 & \dots & 0 & 0 \\
            \vdots & & \ddots & & \vdots \\
            0 & 0 & \dots & 1 & 0 \\
            0 & 0 & \dots & 0 & 1
        \end{pmatrix} $$
        \item The adjecency matrix of relation $ \leq $ on the set $ \left\{1,2,3,4,5\right\} $ is the upper triangular matirx:
        $$ \begin{pmatrix}
            1 & 1 & 1 & 1 & 1\\
            0 & 1 & 1 & 1 & 1\\
            0 & 0 & 1 & 1 & 1\\
            0 & 0 & 0 & 1 & 1\\
            0 & 0 & 0 & 0 & 1\\

        \end{pmatrix} $$
    \end{enumerate}
\end{example}

Some relations have special properties:
\begin{definition}[Special relation properties]
    Let $ R $ be a relation on set $S$. Then $R$ is called
    \begin{itemize}
        \item \emph{Reflexive} if for all $ x \in S $ we have $ (x,x) \in R $
        \item \emph{Irreflexive} if for all $ x \in S $ we have $ (x,x) \notin R $
        \item \emph{Symmetric} if for all $ x,y \in S $ we have $ xRy \implies yRx $
        \item \emph{Antisymmetric} if for all $ x,y \in S $ we have that $ xRy \text{ and } yRx \implies x = y$
        \item \emph{Transitive} if for all $ x,y,z \in S $ we have that $ xRy $ nd $ yRz \implies xRz$
    \end{itemize}
\end{definition}

\subsection{Relations and Directed Graphs}

\begin{definition}[Directed graph]
    A \emph{directed edge} of a set $V$ is an element of $V\times V$. If $ e (v,w) $ is a directed edge of $V$, then
    $v$ is called its \emph{tail} and $w$ its \emph{head}. Both $v$ and $w$ are called \emph{end points} of the edge $e$.
    The \emph{reverse} of the edge $e$ is the edge $ (w,v) $. A \emph{loop} is an edge from a vertex to itself. \par
A \emph{directed graph} (also called \emph(digraph)) $\Gamma = (V,E)$ consists of a set of \emph{vertices} and a subset $E$ of $V\times V$ of (directed) \emph{edges}.
The elements of $V$ are called teh vertices of $\Gamma$ and the elements of $E$ the \emph{edges} of $\Gamma$
\end{definition}

\subsubsection{Some graph theoretical language}
Suppose $ \Gamma = (V,E) $ is a digraph. A \emph{walk} from $v$ to $w$, where $v,w \in V$, is a sequence $ v_0,v_1,\dots,v_k $ of vertices with $ v_0 = v, v_k = w $ and $ (v_i, v_{i+1}) \in E $ for all $ 0 \leq i \le k $.
A \emph{path} from $v$ to $w$ is a walk from $v$ to $w$ in which all vertices, except possibly the first vertex $v$ and the last vertex $w$ are different. \par
An \emph{undericted walk} from $v$ to $w$ is a sequence $ v_0,v_1,\dots,v_k $ of vertices with $ (v_i,v_{i+1}) \in E $ or $ (v_{i+1}, v_i) \in E $ for all $ 0 \leq i \le k $, while an \emph{undirected path} from $v$ to $w$ is an undirected walk in which all vertices except possibly the first and last are different.
The \emph{length} of the (directed or undirected) walk or path is $k$. A \emph{cycle} is a path from $v$ to $v$ of length at least 1. \par
If $v,w \in V$ are vertices of the digraph $\Gamma$, then the \emph{distance} from $v$ to $w$ is the minimum of the lengths of
the paths from $v$ to $w$. The distance is set to $\infty$ (infinity) if there is no path from $v$ to $w$. \par
The digraph is called \emph{weakly connected} if for any two vertices $v$ and $w$ there is an undirected path between
$v$ and $w$. It is \emph{called strongly} connected if there exist paths in both directions. \par
% If W is a subset of V, then the induced subgraph of Γ on W is the digraph (W,E ∩(W ×W)). A (weakly)
% connected component C of Γ is a maximal subset of V such that the induced subgraph is (weakly) connected.
% If we define the relation R on V by vRw if and only if there is an undirected path from v to w, then R is an
% equivalence relation. The weakly connected components of Γ are then the R-equivalence classes.
% A strongly connected component is a maximal subset of V such that the induced subgraph is strongly
% connected.
% Let S be the relation on the set V where vSw if there is an directed path from v to w and from w to v.
% Then S is an equivalence relation. (Proof this!) The strongly connected components are then the Sequivalence classes.
% As we can identify a directed graph with the corresponding relation, we can of course represent the graph
% by its adjacency matrix as well as by a diagram as in 3.1.6. However, as a directed graph Γ = (V,E) defines a
% relation on a set V, there is no need to draw this set twice. The usual way that we draw the graph Γ is to draw
% the vertices of V with arrows from a vertex v ∈ V to a vertex w ∈ V if and only if (v,w) ∈ E.

\begin{proposition}
    Let $ (V,E) $ be a directed graph. Then we have the following.
    \begin{enumerate}
        \item $E$ is reflexive if and only if every vertex $ v \in V $ is in a loop.
        \item $E$ is symmetric if and only if for every edge $ e \in E $, also its reverse is in $E$.
        \item $E$ is transitive if and only if for each walk of length at least 1 starting from $x$ and ending in $y$ we have that $ (x,y) \in E $.
    \end{enumerate}
\end{proposition}

\begin{example}
    The complete directed graph on a vertex set $V$ is the graph in which all vertices are adjacent to each other and tehmselves. This graph is clearly strongly connected. \par
    So, te corresponding relation is reflexive, symmetric and transitive.
\end{example}

\begin{proposition}
    Let $R$ be a relation on the set $V$ which is reflexive, symmetric and transitive. Then all (weakly) connected components of the graph $ \Gamma = (V,R)$ are complete graphs.
\end{proposition}

\begin{definition}[Indegree / Outdegree]
    Let $ \Gamma = (V,E) $ be a digraph and $ v \in V $ a vertex. The \emph{indegree} of $v$ is the number of edges with $v$ as head.
    The \emph{outdegree} of $v$ is teh number of edges with $v$ as tail.
\end{definition}

\subsection{Equivalence relations}
\begin{definition}[Equivalence Relation]
    A relation $R$ on a set $S$ is called an \emph{equivalence relation} on $S$ if and only if it is relfexive, symmetric and transitive.
\end{definition}
\begin{example}
    Consider the plane $ \mathbb{R}^2 $ and in it the set $S$ of straight lines. We call two lines parallel in S if and only if they are equal or do not intersect.
    Notice that two lines in S are parallel if and only if thir slopes are equal. Being parallel defines an equivalence relation on the set $S$.
\end{example}
\begin{example}
    Fix $n \in \mathbb{Z}$, and consider the relation $R$ on $\mathbb{Z}$ by $aRb$ if an only if $a-b$ is divisible by $n$. We also write $ a = b \pmod{n} $. \par
    The relation $R$ is an equivalence realtion. Indeed, suppose $a,b,c \in \mathbb{Z}$. Then
    \begin{enumerate}
        \item $ aRa $ as $ a-a=0 $ is divisible by n.
        \item If $ aRb $, then $ a-b $ is divisible by $n$ and hence also $ b - a $. Thus $ bRa $.
        \item If $ aRb, bRc $, then $n$ divides both $ a-b $ and $ b-c $ and then also $ (a-b)+(b-c) = a-c $. So $ aRc $
    \end{enumerate}
\end{example}

\begin{example}
    Let $\Pi$ be a partition of the set $S$. We define the relation $R_\Pi$ as follows: $a,b \in S$ are in relation $R_\Pi$
    if and only if there is a subset $X$ of $S$ in $\Pi$ containing both $a$ and $b$. We check that the relation $R_\Pi$ is an equivalence relation on $S$.
    \begin{itemize}
        \item Reflexivity: Let $a \in S$. Then there is an $X \in \Pi$ containing a. Hence, $a,a \in X$ and $a R_\Pi a$
        \item Symmetry: Let $a R_\Pi b$. Then there is an $X \in \Pi$ with $a,b \in X$. But then also $b,a \in X$ and $b R_\Pi a$
        \item Transitivity: If $a, b, c \in S$ with $a R_\Pi b$ and $b R_\Pi c$, then there are $X,Y \in \Pi$ with $a,b \in X$ and $b,c \in Y$.
        However, then $b$ is in both $X$ and $Y$. But then, as $\Pi$ partitions $S$, we have $X = Y$. So $a,c \in X$ and $a R_\Pi c$
    \end{itemize}
\end{example}

\begin{lemma}
    Let $R$ be an equivalence relation on a set $S$. If $b\in \left[a\right]_R$, then $ \left[b\right]_R = \left[a\right]_R$
\end{lemma}
\begin{proof}[Proof]
    Suppose $ b \in \left[a\right]_R $. Thus $aRb$. If $ c \in \left[b\right]_R $, then $bRc$ and, as $aRb$, we have by transitivity $aRc$.
    In particular, $ [b]_R \subseteq [a]_R $.\par
    Since, by symmetry of $R$, $aRb$ implies $bRa$ and hence $a \in [b]_R$, we similarly get $ [a]_R \subseteq [b]_R $.
\end{proof}

\begin{definition}[Equivalence classes]
    Let $R$ be an equivalence relation on a aset $S$. Then the sets $ [s]_R $, where $ s \in S $ are called the $R$-\emph{equivalence} calsses on S. \par
    We denote the set of $R$-equivalence classes by $ S/R $
\end{definition}
% \begin{definition}[name of the definition]

% \end{definition}

\begin{theorem}
    Let $R$ be an equivalence relation on a set $S$. Then the set $S/R$ of R-equivalence classes partions the set $S$.
\end{theorem}
\begin{proof}[Proof]
    Let $ \Pi_R $ be the set of $R$-equivalence classes. Then by reflexivity of $R$ we find that each element $ a \in S $
    is inside the class $ \left[a\right]_R \Pi_R $.

    If an element $ a \in S $ is in the classes $ \left[b\right]_R and \left[c\right]_R $ of $ \Pi $, then by the previous lemma
    we find $ \left[b\right]_R = \left[a\right]_R $ and $ \left[c\right]_R = \left[a\right]_R $. In particular, $ \left[b\right]_R = \left[c\right]_R $.
    Thus each element $ a \in S $ is inside an unique member of $ \Pi_R $, which therefore is a partition of $S$.
\end{proof}

\begin{example}[Construction of $\mathbb{Q}$]
    The rational numbers can be constructed from integers with the help of an equivalence relation.

    We consider the set $V = Z \times Z \setminus \{0\}$. On $V$ we define the relation $\equiv$ by
    $$ (a,b) \equiv (c,d) \iff a \cdot d = b \cdot c $$
    for all $ (a,b) $ and $ (c,d) $ in $V$.

    Now we denote the $ \equiv $-equivalence class of a pair ($a,b$) by $ \frac{a}{b} $.
\end{example}

\subsection{Composition of relations}
If $R_1$ and $R_2$ are relations between a set $S$ and a set $T$, then we can form new relations
by taking the intersection $R_1 \cap R_2$ or the union $R_1 \cup R_2$. Also the complement of $R_1$
in $R_2$, $R_1 \setminus R_2$ is a new relation. Furhtermore, we can consider the relation $R^{\top}$
(sometimes also denoted by $R^{-1}, R^{\sim} \text{ or } R^{\vee}$) from $T$ to $S$ as the relation
$ \{(t,s) \in T \times S \mid (s,t) \in R\} $

Another way of making new relations out of old ones is the following. If $R_1$ is a relation between $S$ and
$T$ and $R_2$ is a relation between $T$ and $U$, then the \emph{composition} or product $R=R_1;R_2$ (sometimes
denoted by $R_2 \circ R_1$ or $R_1 * R_2$) is the relation between $S$ and $U$ defined by $sRu$ for $s \in S$ and $u \in U$, if and
only if there is a $t \in T$ with $sR_1t$ and $tR_2u$.

\begin{example}
    $ R_1 = \left\{(1,2),(2,3),(3,3),(2,4)\right\} $ and $R_2 = \left\{(1,a), (2,b), (3,c), (3,d)\right\}$.
    Then $ R_1;R_2 = \left\{(1,b), (2,c), (3,c), (2,d)\right\} $.
\end{example}

We get the adjecency matrix of a composition by multiplying the respective adjecency matrices and then replacing
all non-zero entries with 1.

\begin{example}
    Suppose $R_1 = $ $\{(1,2),(2,3),(3,3), (2,4), (3,1)\}$ and $R_2$ is the relation \{\(\left(1,1\right)\),
    \(\left(2,3\right)\), \(\left(3,1\right)\), \(\left(3,3\right)\), \(\left(4,2\right)\)\}
    Then the adjecency matrices $A_1$ and $A_2$ for $R_1$ and $R_2$ are
    \[
        A_1 = \begin{pmatrix}
            0 & 1& 0& 0 \\
            0 & 0 & 1 & 1 \\
            1 & 0 & 1 & 0
        \end{pmatrix},
        A_2 = \begin{pmatrix}
            1 & 0 & 0 \\
            0 & 0 & 1 \\
            1 & 0 & 1 \\
            0 & 1 & 0
        \end{pmatrix}
    \]
    The product of these matrices equals
    $$ M = \begin{pmatrix}
        0&0&1 \\
        1&1&1 \\
        2&0&1
    \end{pmatrix} $$
    So the adjecency matrix of $R_1;R_2$ is
    $$\begin{pmatrix}
        0&0&1 \\
        1&1&1 \\
        1&0&1
    \end{pmatrix}$$
\end{example}

\begin{proposition}
    Suppose $R_1$ si a relation from $S$ to $T$, $R_2$ a relation from $T$ to $U$ and $R_3$ a realtion from $U$ to $V$.
    Then $R_1;(R_2;R_3) = (R_1;R_2);R_3$.

    Composing relations is associative.
\end{proposition}

\subsection{Transitive Closure}

\begin{lemma}\label{lemma:3.5.1}
    Let $ \mathscr{C} $ be a collection of relations $R$ on a set $S$. If all relations $R$ in $\mathscr{C}$ are transitive (symmetric or reflexive),
    then the relation $ \bigcap_{R \in \mathscr{C}} R$ is also transitive (symmetric or transitive, respectively).
\end{lemma}

\begin{proof}[Proof]
    Let $ \bar{R} = \bigcap_{R \in \mathscr{C}}R $. Suppose all memebers of $ \mathscr{C} $ are transitive. Then for all $ a,b,c \in S $ with $ a\bar{R}b $
    and $ b\bar{R}c $ we have $aRb$ and $bRc$ for all $ R \in \mathscr{C} $. Thus by transitivity of each $ R \in \mathscr{C} $ we also have $ aRc $ for each $R \in \mathscr{C}$.
    Thus we find $ a \bar{R}c $. Hence $ \bar{R} $ is transitive.
\end{proof}

The above lemma makes it possible to define the \emph{reflexive, symmetric, or transitive closure}
of a relation $R$ on a set $S$. It is the smallest refexive, symmetric or transitive
relation containing $R$. This means, as follows from \cref{lemma:3.5.1}, it is the
intersection $ \bigcap_{R^\prime \in \mathscr{C}}R^\prime $, where $ \mathscr{C} $
is the collection of all reflexive, symmetric, or transitive relations containing $R$.

\begin{proposition}
    $ \bigcup_{n>0}R^n $ is the transitive closure of the relation $R$.
\end{proposition}

\begin{proof}[Proof]
    Define $ \bar{R} = \bigcup_{n>0}R^n $. We prove transitivity of $ \bar{R} $. Let $ a\bar{R}b $
    and $ b\bar{R}c $, then there are sequence $ a = a_1,\dots,a_k = b $ and $ b = b_1,\dots,b_l = c $
    with $ a_iRa_{i+1} $ and $ b_iRb_{i+1} $. But then the sequence $ a=a_1=c_1,\dots,c_k=a_k=b_1,\dots,c_{k+l-1}=b_l=c$
    is a sequence from $a$ to $c$ with $ c_iRc_{i+1} $. Hence $ aR^{k+l-2}c $ and $ a\bar{R}c $.
\end{proof}

The transitive, symmetric and reflexive closure of a relation $R$ is an equivalence relation.
In terms of the graph $ \Gamma_R $, the equivalence classes are the strongly connected
componenets of $ \Gamma_R $.

\begin{algorithm}[H]
    Warhall's Algorithm
\end{algorithm}
